{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "OUXHsYYZU0hn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cDLKgbUGSLDK",
        "outputId": "0d254790-ebb1-44aa-b574-510c5ee9bef3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([[[[ 59,  62,  63],\n",
              "           [ 43,  46,  45],\n",
              "           [ 50,  48,  43],\n",
              "           ...,\n",
              "           [158, 132, 108],\n",
              "           [152, 125, 102],\n",
              "           [148, 124, 103]],\n",
              "  \n",
              "          [[ 16,  20,  20],\n",
              "           [  0,   0,   0],\n",
              "           [ 18,   8,   0],\n",
              "           ...,\n",
              "           [123,  88,  55],\n",
              "           [119,  83,  50],\n",
              "           [122,  87,  57]],\n",
              "  \n",
              "          [[ 25,  24,  21],\n",
              "           [ 16,   7,   0],\n",
              "           [ 49,  27,   8],\n",
              "           ...,\n",
              "           [118,  84,  50],\n",
              "           [120,  84,  50],\n",
              "           [109,  73,  42]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[208, 170,  96],\n",
              "           [201, 153,  34],\n",
              "           [198, 161,  26],\n",
              "           ...,\n",
              "           [160, 133,  70],\n",
              "           [ 56,  31,   7],\n",
              "           [ 53,  34,  20]],\n",
              "  \n",
              "          [[180, 139,  96],\n",
              "           [173, 123,  42],\n",
              "           [186, 144,  30],\n",
              "           ...,\n",
              "           [184, 148,  94],\n",
              "           [ 97,  62,  34],\n",
              "           [ 83,  53,  34]],\n",
              "  \n",
              "          [[177, 144, 116],\n",
              "           [168, 129,  94],\n",
              "           [179, 142,  87],\n",
              "           ...,\n",
              "           [216, 184, 140],\n",
              "           [151, 118,  84],\n",
              "           [123,  92,  72]]],\n",
              "  \n",
              "  \n",
              "         [[[154, 177, 187],\n",
              "           [126, 137, 136],\n",
              "           [105, 104,  95],\n",
              "           ...,\n",
              "           [ 91,  95,  71],\n",
              "           [ 87,  90,  71],\n",
              "           [ 79,  81,  70]],\n",
              "  \n",
              "          [[140, 160, 169],\n",
              "           [145, 153, 154],\n",
              "           [125, 125, 118],\n",
              "           ...,\n",
              "           [ 96,  99,  78],\n",
              "           [ 77,  80,  62],\n",
              "           [ 71,  73,  61]],\n",
              "  \n",
              "          [[140, 155, 164],\n",
              "           [139, 146, 149],\n",
              "           [115, 115, 112],\n",
              "           ...,\n",
              "           [ 79,  82,  64],\n",
              "           [ 68,  70,  55],\n",
              "           [ 67,  69,  55]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[175, 167, 166],\n",
              "           [156, 154, 160],\n",
              "           [154, 160, 170],\n",
              "           ...,\n",
              "           [ 42,  34,  36],\n",
              "           [ 61,  53,  57],\n",
              "           [ 93,  83,  91]],\n",
              "  \n",
              "          [[165, 154, 128],\n",
              "           [156, 152, 130],\n",
              "           [159, 161, 142],\n",
              "           ...,\n",
              "           [103,  93,  96],\n",
              "           [123, 114, 120],\n",
              "           [131, 121, 131]],\n",
              "  \n",
              "          [[163, 148, 120],\n",
              "           [158, 148, 122],\n",
              "           [163, 156, 133],\n",
              "           ...,\n",
              "           [143, 133, 139],\n",
              "           [143, 134, 142],\n",
              "           [143, 133, 144]]],\n",
              "  \n",
              "  \n",
              "         [[[255, 255, 255],\n",
              "           [253, 253, 253],\n",
              "           [253, 253, 253],\n",
              "           ...,\n",
              "           [253, 253, 253],\n",
              "           [253, 253, 253],\n",
              "           [253, 253, 253]],\n",
              "  \n",
              "          [[255, 255, 255],\n",
              "           [255, 255, 255],\n",
              "           [255, 255, 255],\n",
              "           ...,\n",
              "           [255, 255, 255],\n",
              "           [255, 255, 255],\n",
              "           [255, 255, 255]],\n",
              "  \n",
              "          [[255, 255, 255],\n",
              "           [254, 254, 254],\n",
              "           [254, 254, 254],\n",
              "           ...,\n",
              "           [254, 254, 254],\n",
              "           [254, 254, 254],\n",
              "           [254, 254, 254]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[113, 120, 112],\n",
              "           [111, 118, 111],\n",
              "           [105, 112, 106],\n",
              "           ...,\n",
              "           [ 72,  81,  80],\n",
              "           [ 72,  80,  79],\n",
              "           [ 72,  80,  79]],\n",
              "  \n",
              "          [[111, 118, 110],\n",
              "           [104, 111, 104],\n",
              "           [ 99, 106,  98],\n",
              "           ...,\n",
              "           [ 68,  75,  73],\n",
              "           [ 70,  76,  75],\n",
              "           [ 78,  84,  82]],\n",
              "  \n",
              "          [[106, 113, 105],\n",
              "           [ 99, 106,  98],\n",
              "           [ 95, 102,  94],\n",
              "           ...,\n",
              "           [ 78,  85,  83],\n",
              "           [ 79,  85,  83],\n",
              "           [ 80,  86,  84]]],\n",
              "  \n",
              "  \n",
              "         ...,\n",
              "  \n",
              "  \n",
              "         [[[ 35, 178, 235],\n",
              "           [ 40, 176, 239],\n",
              "           [ 42, 176, 241],\n",
              "           ...,\n",
              "           [ 99, 177, 219],\n",
              "           [ 79, 147, 197],\n",
              "           [ 89, 148, 189]],\n",
              "  \n",
              "          [[ 57, 182, 234],\n",
              "           [ 44, 184, 250],\n",
              "           [ 50, 183, 240],\n",
              "           ...,\n",
              "           [156, 182, 200],\n",
              "           [141, 177, 206],\n",
              "           [116, 149, 175]],\n",
              "  \n",
              "          [[ 98, 197, 237],\n",
              "           [ 64, 189, 252],\n",
              "           [ 69, 192, 245],\n",
              "           ...,\n",
              "           [188, 195, 206],\n",
              "           [119, 135, 147],\n",
              "           [ 61,  79,  90]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[ 73,  79,  77],\n",
              "           [ 53,  63,  68],\n",
              "           [ 54,  68,  80],\n",
              "           ...,\n",
              "           [ 17,  40,  64],\n",
              "           [ 21,  36,  51],\n",
              "           [ 33,  48,  49]],\n",
              "  \n",
              "          [[ 61,  68,  75],\n",
              "           [ 55,  70,  86],\n",
              "           [ 57,  79, 103],\n",
              "           ...,\n",
              "           [ 24,  48,  72],\n",
              "           [ 17,  35,  53],\n",
              "           [  7,  23,  32]],\n",
              "  \n",
              "          [[ 44,  56,  73],\n",
              "           [ 46,  66,  88],\n",
              "           [ 49,  77, 105],\n",
              "           ...,\n",
              "           [ 27,  52,  77],\n",
              "           [ 21,  43,  66],\n",
              "           [ 12,  31,  50]]],\n",
              "  \n",
              "  \n",
              "         [[[189, 211, 240],\n",
              "           [186, 208, 236],\n",
              "           [185, 207, 235],\n",
              "           ...,\n",
              "           [175, 195, 224],\n",
              "           [172, 194, 222],\n",
              "           [169, 194, 220]],\n",
              "  \n",
              "          [[194, 210, 239],\n",
              "           [191, 207, 236],\n",
              "           [190, 206, 235],\n",
              "           ...,\n",
              "           [173, 192, 220],\n",
              "           [171, 191, 218],\n",
              "           [167, 190, 216]],\n",
              "  \n",
              "          [[208, 219, 244],\n",
              "           [205, 216, 240],\n",
              "           [204, 215, 239],\n",
              "           ...,\n",
              "           [175, 191, 217],\n",
              "           [172, 190, 216],\n",
              "           [169, 191, 215]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[207, 199, 181],\n",
              "           [203, 195, 175],\n",
              "           [203, 196, 173],\n",
              "           ...,\n",
              "           [135, 132, 127],\n",
              "           [162, 158, 150],\n",
              "           [168, 163, 151]],\n",
              "  \n",
              "          [[198, 190, 170],\n",
              "           [189, 181, 159],\n",
              "           [180, 172, 147],\n",
              "           ...,\n",
              "           [178, 171, 160],\n",
              "           [175, 169, 156],\n",
              "           [175, 169, 154]],\n",
              "  \n",
              "          [[198, 189, 173],\n",
              "           [189, 181, 162],\n",
              "           [178, 170, 149],\n",
              "           ...,\n",
              "           [195, 184, 169],\n",
              "           [196, 189, 171],\n",
              "           [195, 190, 171]]],\n",
              "  \n",
              "  \n",
              "         [[[229, 229, 239],\n",
              "           [236, 237, 247],\n",
              "           [234, 236, 247],\n",
              "           ...,\n",
              "           [217, 219, 233],\n",
              "           [221, 223, 234],\n",
              "           [222, 223, 233]],\n",
              "  \n",
              "          [[222, 221, 229],\n",
              "           [239, 239, 249],\n",
              "           [233, 234, 246],\n",
              "           ...,\n",
              "           [223, 223, 236],\n",
              "           [227, 228, 238],\n",
              "           [210, 211, 220]],\n",
              "  \n",
              "          [[213, 206, 211],\n",
              "           [234, 232, 239],\n",
              "           [231, 233, 244],\n",
              "           ...,\n",
              "           [220, 220, 232],\n",
              "           [220, 219, 232],\n",
              "           [202, 203, 215]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[150, 143, 135],\n",
              "           [140, 135, 127],\n",
              "           [132, 127, 120],\n",
              "           ...,\n",
              "           [224, 222, 218],\n",
              "           [230, 228, 225],\n",
              "           [241, 241, 238]],\n",
              "  \n",
              "          [[137, 132, 126],\n",
              "           [130, 127, 120],\n",
              "           [125, 121, 115],\n",
              "           ...,\n",
              "           [181, 180, 178],\n",
              "           [202, 201, 198],\n",
              "           [212, 211, 207]],\n",
              "  \n",
              "          [[122, 119, 114],\n",
              "           [118, 116, 110],\n",
              "           [120, 116, 111],\n",
              "           ...,\n",
              "           [179, 177, 173],\n",
              "           [164, 164, 162],\n",
              "           [163, 163, 161]]]], dtype=uint8),\n",
              "  array([[6],\n",
              "         [9],\n",
              "         [9],\n",
              "         ...,\n",
              "         [9],\n",
              "         [1],\n",
              "         [1]], dtype=uint8)),\n",
              " (array([[[[158, 112,  49],\n",
              "           [159, 111,  47],\n",
              "           [165, 116,  51],\n",
              "           ...,\n",
              "           [137,  95,  36],\n",
              "           [126,  91,  36],\n",
              "           [116,  85,  33]],\n",
              "  \n",
              "          [[152, 112,  51],\n",
              "           [151, 110,  40],\n",
              "           [159, 114,  45],\n",
              "           ...,\n",
              "           [136,  95,  31],\n",
              "           [125,  91,  32],\n",
              "           [119,  88,  34]],\n",
              "  \n",
              "          [[151, 110,  47],\n",
              "           [151, 109,  33],\n",
              "           [158, 111,  36],\n",
              "           ...,\n",
              "           [139,  98,  34],\n",
              "           [130,  95,  34],\n",
              "           [120,  89,  33]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[ 68, 124, 177],\n",
              "           [ 42, 100, 148],\n",
              "           [ 31,  88, 137],\n",
              "           ...,\n",
              "           [ 38,  97, 146],\n",
              "           [ 13,  64, 108],\n",
              "           [ 40,  85, 127]],\n",
              "  \n",
              "          [[ 61, 116, 168],\n",
              "           [ 49, 102, 148],\n",
              "           [ 35,  85, 132],\n",
              "           ...,\n",
              "           [ 26,  82, 130],\n",
              "           [ 29,  82, 126],\n",
              "           [ 20,  64, 107]],\n",
              "  \n",
              "          [[ 54, 107, 160],\n",
              "           [ 56, 105, 149],\n",
              "           [ 45,  89, 132],\n",
              "           ...,\n",
              "           [ 24,  77, 124],\n",
              "           [ 34,  84, 129],\n",
              "           [ 21,  67, 110]]],\n",
              "  \n",
              "  \n",
              "         [[[235, 235, 235],\n",
              "           [231, 231, 231],\n",
              "           [232, 232, 232],\n",
              "           ...,\n",
              "           [233, 233, 233],\n",
              "           [233, 233, 233],\n",
              "           [232, 232, 232]],\n",
              "  \n",
              "          [[238, 238, 238],\n",
              "           [235, 235, 235],\n",
              "           [235, 235, 235],\n",
              "           ...,\n",
              "           [236, 236, 236],\n",
              "           [236, 236, 236],\n",
              "           [235, 235, 235]],\n",
              "  \n",
              "          [[237, 237, 237],\n",
              "           [234, 234, 234],\n",
              "           [234, 234, 234],\n",
              "           ...,\n",
              "           [235, 235, 235],\n",
              "           [235, 235, 235],\n",
              "           [234, 234, 234]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[ 87,  99,  89],\n",
              "           [ 43,  51,  37],\n",
              "           [ 19,  23,  11],\n",
              "           ...,\n",
              "           [169, 184, 179],\n",
              "           [182, 197, 193],\n",
              "           [188, 202, 201]],\n",
              "  \n",
              "          [[ 82,  96,  82],\n",
              "           [ 46,  57,  36],\n",
              "           [ 36,  44,  22],\n",
              "           ...,\n",
              "           [174, 189, 183],\n",
              "           [185, 200, 196],\n",
              "           [187, 202, 200]],\n",
              "  \n",
              "          [[ 85, 101,  83],\n",
              "           [ 62,  75,  48],\n",
              "           [ 58,  67,  38],\n",
              "           ...,\n",
              "           [168, 183, 178],\n",
              "           [180, 195, 191],\n",
              "           [186, 200, 199]]],\n",
              "  \n",
              "  \n",
              "         [[[158, 190, 222],\n",
              "           [158, 187, 218],\n",
              "           [139, 166, 194],\n",
              "           ...,\n",
              "           [228, 231, 234],\n",
              "           [237, 239, 243],\n",
              "           [238, 241, 246]],\n",
              "  \n",
              "          [[170, 200, 229],\n",
              "           [172, 199, 226],\n",
              "           [151, 176, 201],\n",
              "           ...,\n",
              "           [232, 232, 236],\n",
              "           [246, 246, 250],\n",
              "           [246, 247, 251]],\n",
              "  \n",
              "          [[174, 201, 225],\n",
              "           [176, 200, 222],\n",
              "           [157, 179, 199],\n",
              "           ...,\n",
              "           [230, 229, 232],\n",
              "           [250, 249, 251],\n",
              "           [245, 244, 247]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[ 31,  40,  45],\n",
              "           [ 30,  39,  44],\n",
              "           [ 26,  35,  40],\n",
              "           ...,\n",
              "           [ 37,  40,  46],\n",
              "           [  9,  13,  14],\n",
              "           [  4,   7,   5]],\n",
              "  \n",
              "          [[ 23,  34,  39],\n",
              "           [ 27,  38,  43],\n",
              "           [ 25,  36,  41],\n",
              "           ...,\n",
              "           [ 19,  20,  24],\n",
              "           [  4,   6,   3],\n",
              "           [  5,   7,   3]],\n",
              "  \n",
              "          [[ 28,  41,  47],\n",
              "           [ 30,  43,  50],\n",
              "           [ 32,  45,  52],\n",
              "           ...,\n",
              "           [  5,   6,   8],\n",
              "           [  4,   5,   3],\n",
              "           [  7,   8,   7]]],\n",
              "  \n",
              "  \n",
              "         ...,\n",
              "  \n",
              "  \n",
              "         [[[ 20,  15,  12],\n",
              "           [ 19,  14,  11],\n",
              "           [ 15,  14,  11],\n",
              "           ...,\n",
              "           [ 10,   9,   7],\n",
              "           [ 12,  11,   9],\n",
              "           [ 13,  12,  10]],\n",
              "  \n",
              "          [[ 21,  16,  13],\n",
              "           [ 20,  16,  13],\n",
              "           [ 18,  17,  12],\n",
              "           ...,\n",
              "           [ 10,   9,   7],\n",
              "           [ 10,   9,   7],\n",
              "           [ 12,  11,   9]],\n",
              "  \n",
              "          [[ 21,  16,  13],\n",
              "           [ 21,  17,  12],\n",
              "           [ 20,  18,  11],\n",
              "           ...,\n",
              "           [ 12,  11,   9],\n",
              "           [ 12,  11,   9],\n",
              "           [ 13,  12,  10]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[ 33,  25,  13],\n",
              "           [ 34,  26,  15],\n",
              "           [ 34,  26,  15],\n",
              "           ...,\n",
              "           [ 28,  25,  52],\n",
              "           [ 29,  25,  58],\n",
              "           [ 23,  20,  42]],\n",
              "  \n",
              "          [[ 33,  25,  14],\n",
              "           [ 34,  26,  15],\n",
              "           [ 34,  26,  15],\n",
              "           ...,\n",
              "           [ 27,  24,  52],\n",
              "           [ 27,  24,  56],\n",
              "           [ 25,  22,  47]],\n",
              "  \n",
              "          [[ 31,  23,  12],\n",
              "           [ 32,  24,  13],\n",
              "           [ 33,  25,  14],\n",
              "           ...,\n",
              "           [ 24,  23,  50],\n",
              "           [ 26,  23,  53],\n",
              "           [ 25,  20,  47]]],\n",
              "  \n",
              "  \n",
              "         [[[ 25,  40,  12],\n",
              "           [ 15,  36,   3],\n",
              "           [ 23,  41,  18],\n",
              "           ...,\n",
              "           [ 61,  82,  78],\n",
              "           [ 92, 113, 112],\n",
              "           [ 75,  89,  92]],\n",
              "  \n",
              "          [[ 12,  25,   6],\n",
              "           [ 20,  37,   7],\n",
              "           [ 24,  36,  15],\n",
              "           ...,\n",
              "           [115, 134, 138],\n",
              "           [149, 168, 177],\n",
              "           [104, 117, 131]],\n",
              "  \n",
              "          [[ 12,  25,  11],\n",
              "           [ 15,  29,   6],\n",
              "           [ 34,  40,  24],\n",
              "           ...,\n",
              "           [154, 172, 182],\n",
              "           [157, 175, 192],\n",
              "           [116, 129, 151]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[100, 129,  81],\n",
              "           [103, 132,  84],\n",
              "           [104, 134,  86],\n",
              "           ...,\n",
              "           [ 97, 128,  84],\n",
              "           [ 98, 126,  84],\n",
              "           [ 91, 121,  79]],\n",
              "  \n",
              "          [[103, 132,  83],\n",
              "           [104, 131,  83],\n",
              "           [107, 135,  87],\n",
              "           ...,\n",
              "           [101, 132,  87],\n",
              "           [ 99, 127,  84],\n",
              "           [ 92, 121,  79]],\n",
              "  \n",
              "          [[ 95, 126,  78],\n",
              "           [ 95, 123,  76],\n",
              "           [101, 128,  81],\n",
              "           ...,\n",
              "           [ 93, 124,  80],\n",
              "           [ 95, 123,  81],\n",
              "           [ 92, 120,  80]]],\n",
              "  \n",
              "  \n",
              "         [[[ 73,  78,  75],\n",
              "           [ 98, 103, 113],\n",
              "           [ 99, 106, 114],\n",
              "           ...,\n",
              "           [135, 150, 152],\n",
              "           [135, 149, 154],\n",
              "           [203, 215, 223]],\n",
              "  \n",
              "          [[ 69,  73,  70],\n",
              "           [ 84,  89,  97],\n",
              "           [ 68,  75,  81],\n",
              "           ...,\n",
              "           [ 85,  95,  89],\n",
              "           [ 71,  82,  80],\n",
              "           [120, 133, 135]],\n",
              "  \n",
              "          [[ 69,  73,  70],\n",
              "           [ 90,  95, 100],\n",
              "           [ 62,  71,  74],\n",
              "           ...,\n",
              "           [ 74,  81,  70],\n",
              "           [ 53,  62,  54],\n",
              "           [ 62,  74,  69]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[123, 128,  96],\n",
              "           [132, 132, 102],\n",
              "           [129, 128, 100],\n",
              "           ...,\n",
              "           [108, 107,  88],\n",
              "           [ 62,  60,  55],\n",
              "           [ 27,  27,  28]],\n",
              "  \n",
              "          [[115, 121,  91],\n",
              "           [123, 124,  95],\n",
              "           [129, 126,  99],\n",
              "           ...,\n",
              "           [115, 116,  94],\n",
              "           [ 66,  65,  59],\n",
              "           [ 27,  27,  27]],\n",
              "  \n",
              "          [[116, 120,  90],\n",
              "           [121, 122,  94],\n",
              "           [129, 128, 101],\n",
              "           ...,\n",
              "           [116, 115,  94],\n",
              "           [ 68,  65,  58],\n",
              "           [ 27,  26,  26]]]], dtype=uint8),\n",
              "  array([[3],\n",
              "         [8],\n",
              "         [8],\n",
              "         ...,\n",
              "         [5],\n",
              "         [1],\n",
              "         [7]], dtype=uint8)))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "tf.keras.datasets.cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()"
      ],
      "metadata": {
        "id": "7tIPUQAASQIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_full.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jY-mS6DDSRV_",
        "outputId": "34f67052-8670-4d7e-9c9a-792aa037b5a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
        "X_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]"
      ],
      "metadata": {
        "id": "xAxIWxaMSRTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnLzW5OYSRRO",
        "outputId": "b9956274-e931-4a58-dd5e-02b77d36c2c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_valid, X_test = X_train / 255., X_valid / 255., X_test / 255."
      ],
      "metadata": {
        "id": "xC-CO4ATSRPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Flatten(input_shape = [32,32,3]))\n",
        "for layer in range(100):\n",
        "  model.add(tf.keras.layers.Dense(100, activation = 'selu',\n",
        "                                  kernel_initializer = 'lecun_normal'))\n",
        "model.add(tf.keras.layers.Dense(10, activation = 'softmax'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0BIJXGrm7_P",
        "outputId": "a9ef8bb2-99e4-4bb8-ff3b-2a1ffe8d9453"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'sparse_categorical_crossentropy',\n",
        "              optimizer = tf.keras.optimizers.SGD(learning_rate = 1e-3), metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "1fCj0quVbfuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pixel_means = X_train.mean(axis=0, keepdims = True)\n",
        "pixel_stds = X_train.std(axis=0, keepdims=True)\n",
        "X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
        "X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
        "X_test_scaled = (X_test - pixel_means) / pixel_stds"
      ],
      "metadata": {
        "id": "_G5ETGm2bfr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train_scaled, y_train, epochs = 5,\n",
        "                    validation_data = (X_valid_scaled, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4Z2Yy4pbfpC",
        "outputId": "51348f8d-54b5-4c53-ab25-2e4700cd2552"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 20ms/step - accuracy: 0.1507 - loss: 2.2644 - val_accuracy: 0.1018 - val_loss: 2.4470\n",
            "Epoch 2/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 19ms/step - accuracy: 0.1795 - loss: 2.1305 - val_accuracy: 0.2256 - val_loss: 2.0710\n",
            "Epoch 3/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 20ms/step - accuracy: 0.2029 - loss: 2.0976 - val_accuracy: 0.1712 - val_loss: 2.2226\n",
            "Epoch 4/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 19ms/step - accuracy: 0.1567 - loss: 2.2348 - val_accuracy: 0.1604 - val_loss: 2.1575\n",
            "Epoch 5/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.1817 - loss: 2.1291 - val_accuracy: 0.2306 - val_loss: 2.0670\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "yY31Ae4Sbfmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Flatten(input_shape = [32, 32, 3]))\n",
        "for layer in range(100):\n",
        "  model.add(tf.keras.layers.Dense(100, activation = 'relu',\n",
        "                                  kernel_initializer = 'he_normal'))\n",
        "model.add(tf.keras.layers.Dense(10, activation = 'softmax'))"
      ],
      "metadata": {
        "id": "0I_Uu5yybfkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'sparse_categorical_crossentropy',\n",
        "              optimizer = tf.keras.optimizers.SGD(learning_rate = 1e-3),\n",
        "              metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "BqDSkFmebfhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs = 5,\n",
        "                    validation_data = (X_valid, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BYVapq-nuHK",
        "outputId": "b28f6453-4d3a-47b8-b60e-4755f38d235a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 18ms/step - accuracy: 0.1166 - loss: 2.2816 - val_accuracy: 0.1748 - val_loss: 2.1649\n",
            "Epoch 2/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 18ms/step - accuracy: 0.1719 - loss: 2.1265 - val_accuracy: 0.2052 - val_loss: 2.0825\n",
            "Epoch 3/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 18ms/step - accuracy: 0.1951 - loss: 2.0517 - val_accuracy: 0.1844 - val_loss: 2.1780\n",
            "Epoch 4/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 17ms/step - accuracy: 0.1953 - loss: 2.0299 - val_accuracy: 0.2142 - val_loss: 2.0104\n",
            "Epoch 5/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 18ms/step - accuracy: 0.2065 - loss: 2.0061 - val_accuracy: 0.2154 - val_loss: 2.0174\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "E5Hdx1l2nuD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=[32, 32, 3]),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(300, activation=\"relu\",\n",
        "                          kernel_initializer=\"he_normal\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\",\n",
        "                          kernel_initializer=\"he_normal\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ],
      "metadata": {
        "id": "veVTMEFRnuB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[(var.name, var.trainable) for var in model.layers[1].variables]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3b3_Ddrnt_p",
        "outputId": "d51aca2e-9689-45df-e0fd-7510df9ed65a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('gamma', True),\n",
              " ('beta', True),\n",
              " ('moving_mean', False),\n",
              " ('moving_variance', False)]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd',\n",
        "              metrics = ['accuracy'])\n",
        "model.fit(X_train, y_train, epochs = 5, validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhC_9kzSnt9Y",
        "outputId": "55d2d5ac-64a9-4dd6-eca0-eba68756177c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.5080 - loss: 1.4011 - val_accuracy: 0.4192 - val_loss: 1.7196\n",
            "Epoch 2/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.5404 - loss: 1.3161 - val_accuracy: 0.4292 - val_loss: 1.6821\n",
            "Epoch 3/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.5648 - loss: 1.2438 - val_accuracy: 0.4434 - val_loss: 1.6351\n",
            "Epoch 4/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.5906 - loss: 1.1790 - val_accuracy: 0.4474 - val_loss: 1.6732\n",
            "Epoch 5/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - accuracy: 0.6145 - loss: 1.1162 - val_accuracy: 0.4598 - val_loss: 1.6401\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x782658f15c10>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "NkpWuo5Fnt7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=[32, 32, 3]),\n",
        "    tf.keras.layers.Dense(300, kernel_initializer=\"he_normal\", use_bias=False),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Activation(\"relu\"),\n",
        "    tf.keras.layers.Dense(100, kernel_initializer=\"he_normal\", use_bias=False),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Activation(\"relu\"),\n",
        "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ],
      "metadata": {
        "id": "8dr1e0aQnt4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=5, validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZArB4zCMoB5G",
        "outputId": "b0552be0-529e-4f21-c02f-9e761716fdc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.3433 - loss: 1.8667 - val_accuracy: 0.4038 - val_loss: 1.6992\n",
            "Epoch 2/2\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.4645 - loss: 1.5186 - val_accuracy: 0.4298 - val_loss: 1.6416\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x782658cb33d0>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.SGD(clipvalue=1.0)        # 1den balaca olanlara deymir, ondan boyukleri normalize edir (bir nov learning_rate i azaldir her ikisi)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer)"
      ],
      "metadata": {
        "id": "xA5XHG_uoG9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.SGD(clipnorm = 1.0)    #butun datani max 1 olmaq sherti ile normalize edir\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer)"
      ],
      "metadata": {
        "id": "rD7-jO6soG4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = [\"T-shirt/top\",\n",
        "               \"Trousers\",\n",
        "               \"Pullover\",\n",
        "               \"Dress\",\n",
        "               \"Coat\",\n",
        "               \"Sandal\",\n",
        "               \"Shirt\",\n",
        "               \"Sneaker\",\n",
        "               \"Bag\",\n",
        "               \"Ankle boot\"]"
      ],
      "metadata": {
        "id": "Uxi7UFX4rHzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_class_id = class_names.index(\"Pullover\")\n",
        "neg_class_id = class_names.index(\"T-shirt/top\")\n",
        "\n",
        "def split_dataset(X, y):\n",
        "  y_for_B = (y == pos_class_id) | (y == neg_class_id)\n",
        "  y_for_B = y_for_B.reshape(-1)\n",
        "  y_A = y[~y_for_B]\n",
        "  y_B = (y[y_for_B] == pos_class_id).astype(np.float32)\n",
        "  old_class_ids = list(set(range(10)) - set([neg_class_id, pos_class_id]))\n",
        "  for old_class_id, new_class_id in zip(old_class_ids, range(8)):\n",
        "    y_A[y_A == old_class_id] = new_class_id   # reorder class ids for A\n",
        "  return ((X[~y_for_B], y_A), (X[y_for_B], y_B))\n",
        "\n",
        "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
        "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
        "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
        "X_train_B = X_train_B[:200]\n",
        "y_train_B = y_train_B[:200]"
      ],
      "metadata": {
        "id": "EsKx0oMVoG2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model_A = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape = [32, 32, 3]),\n",
        "    tf.keras.layers.Dense(100, activation='relu',\n",
        "                          kernel_initializer='he_normal'),\n",
        "    tf.keras.layers.Dense(100, activation='relu',\n",
        "                          kernel_initializer='he_normal'),\n",
        "    tf.keras.layers.Dense(100, activation='relu',\n",
        "                          kernel_initializer='he_normal'),\n",
        "    tf.keras.layers.Dense(8, activation='softmax')\n",
        "])\n",
        "\n",
        "model_A.compile(loss='sparse_categorical_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3),\n",
        "                metrics=['accuracy'])\n",
        "history = model_A.fit(X_train_A, y_train_A, epochs = 20,\n",
        "                      validation_data=(X_valid_A, y_valid_A))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSzzO-eXoG0S",
        "outputId": "7e8ed939-0d88-4824-bbfc-5ac37f39cbaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.2462 - loss: 1.9470 - val_accuracy: 0.3275 - val_loss: 1.7637\n",
            "Epoch 2/20\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.3493 - loss: 1.7225 - val_accuracy: 0.3808 - val_loss: 1.6685\n",
            "Epoch 3/20\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3879 - loss: 1.6363 - val_accuracy: 0.4024 - val_loss: 1.6121\n",
            "Epoch 4/20\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4117 - loss: 1.5816 - val_accuracy: 0.4153 - val_loss: 1.5732\n",
            "Epoch 5/20\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.4278 - loss: 1.5411 - val_accuracy: 0.4320 - val_loss: 1.5431\n",
            "Epoch 6/20\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.4451 - loss: 1.5095 - val_accuracy: 0.4364 - val_loss: 1.5191\n",
            "Epoch 7/20\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.4546 - loss: 1.4835 - val_accuracy: 0.4459 - val_loss: 1.4994\n",
            "Epoch 8/20\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4648 - loss: 1.4609 - val_accuracy: 0.4511 - val_loss: 1.4799\n",
            "Epoch 9/20\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.4729 - loss: 1.4412 - val_accuracy: 0.4573 - val_loss: 1.4644\n",
            "Epoch 10/20\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4809 - loss: 1.4237 - val_accuracy: 0.4643 - val_loss: 1.4503\n",
            "Epoch 11/20\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4867 - loss: 1.4081 - val_accuracy: 0.4695 - val_loss: 1.4375\n",
            "Epoch 12/20\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.4911 - loss: 1.3934 - val_accuracy: 0.4749 - val_loss: 1.4247\n",
            "Epoch 13/20\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.4965 - loss: 1.3798 - val_accuracy: 0.4794 - val_loss: 1.4146\n",
            "Epoch 14/20\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5020 - loss: 1.3675 - val_accuracy: 0.4806 - val_loss: 1.4055\n",
            "Epoch 15/20\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5057 - loss: 1.3560 - val_accuracy: 0.4871 - val_loss: 1.3970\n",
            "Epoch 16/20\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5090 - loss: 1.3455 - val_accuracy: 0.4871 - val_loss: 1.3870\n",
            "Epoch 17/20\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5129 - loss: 1.3351 - val_accuracy: 0.4896 - val_loss: 1.3784\n",
            "Epoch 18/20\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5167 - loss: 1.3254 - val_accuracy: 0.4926 - val_loss: 1.3711\n",
            "Epoch 19/20\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5193 - loss: 1.3162 - val_accuracy: 0.4965 - val_loss: 1.3620\n",
            "Epoch 20/20\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5219 - loss: 1.3072 - val_accuracy: 0.4988 - val_loss: 1.3545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_A.save('my_model_A.keras')"
      ],
      "metadata": {
        "id": "JeyUsnfUoGyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model_B = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape = [32, 32, 3]),\n",
        "    tf.keras.layers.Dense(100, activation='relu',\n",
        "                          kernel_initializer='he_normal'),\n",
        "    tf.keras.layers.Dense(100, activation='relu',\n",
        "                          kernel_initializer='he_normal'),\n",
        "    tf.keras.layers.Dense(100, activation='relu',\n",
        "                          kernel_initializer='he_normal'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_B.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3),\n",
        "                metrics=['accuracy'])\n",
        "history = model_B.fit(X_train_B, y_train_B, epochs = 20,\n",
        "                      validation_data=(X_valid_B, y_valid_B))\n",
        "model.evaluate(X_test_B, y_test_B)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZigbeOvdoGvS",
        "outputId": "5537a880-4b22-4d3a-beaf-a3e4686463aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.4253 - loss: 0.7227 - val_accuracy: 0.4599 - val_loss: 0.7094\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4396 - loss: 0.7105 - val_accuracy: 0.4753 - val_loss: 0.7038\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4428 - loss: 0.7031 - val_accuracy: 0.4969 - val_loss: 0.6978\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4606 - loss: 0.6960 - val_accuracy: 0.5288 - val_loss: 0.6919\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5168 - loss: 0.6889 - val_accuracy: 0.5720 - val_loss: 0.6872\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5510 - loss: 0.6825 - val_accuracy: 0.5947 - val_loss: 0.6825\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5898 - loss: 0.6759 - val_accuracy: 0.6101 - val_loss: 0.6780\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6259 - loss: 0.6693 - val_accuracy: 0.6245 - val_loss: 0.6733\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6456 - loss: 0.6627 - val_accuracy: 0.6368 - val_loss: 0.6690\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6694 - loss: 0.6569 - val_accuracy: 0.6492 - val_loss: 0.6650\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6766 - loss: 0.6520 - val_accuracy: 0.6584 - val_loss: 0.6611\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6848 - loss: 0.6476 - val_accuracy: 0.6595 - val_loss: 0.6579\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7008 - loss: 0.6433 - val_accuracy: 0.6687 - val_loss: 0.6549\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7123 - loss: 0.6395 - val_accuracy: 0.6780 - val_loss: 0.6522\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7159 - loss: 0.6357 - val_accuracy: 0.6831 - val_loss: 0.6495\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7148 - loss: 0.6318 - val_accuracy: 0.6924 - val_loss: 0.6471\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7144 - loss: 0.6283 - val_accuracy: 0.6965 - val_loss: 0.6444\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7253 - loss: 0.6250 - val_accuracy: 0.7006 - val_loss: 0.6418\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7309 - loss: 0.6218 - val_accuracy: 0.7078 - val_loss: 0.6395\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7317 - loss: 0.6187 - val_accuracy: 0.7088 - val_loss: 0.6375\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3550 - loss: 2.7270\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.6567955017089844, 0.36649999022483826]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_A = tf.keras.models.load_model(\"my_model_A.keras\")\n",
        "model_B_on_A = tf.keras.Sequential(model_A.layers[:-1])   #output layeri goturme\n",
        "model_B_on_A.add(tf.keras.layers.Dense(1, activation='sigmoid'))   # onun yerine bunu elave et"
      ],
      "metadata": {
        "id": "dDGVnRoYoGs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "0VZ3rXgXoGpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_A_clone = tf.keras.models.clone_model(model_A)\n",
        "model_A_clone.set_weights(model_A.get_weights())         #A modelinin clonunu gotururuk ki, B_on_A-i yeniden fit etsek A_nin parametrleri yeniden deyisecek. Ona gore clone yaradiriq ve A modelinin weight-lerini gotururuk"
      ],
      "metadata": {
        "id": "1s1J6GHmoGmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_B_on_A = tf.keras.Sequential(model_A_clone.layers[:-1])\n",
        "model_B_on_A.add(tf.keras.layers.Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "PxNKRNnkoGkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model_B_on_A.layers[:-1]:\n",
        "  layer.trainable = True\n",
        "\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
        "model_B_on_A.compile(loss='binary_crossentropy', optimizer = optimizer,\n",
        "                     metrics=['accuracy'])\n",
        "\n",
        "history = model_B_on_A.fit(X_train_B, y_train_B)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4lnC-_KoGhl",
        "outputId": "920bcd26-e6b0-49da-f462-d6148f9f836e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5360 - loss: 0.8839  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def build_model(seed=42):\n",
        "  tf.random.set_seed(seed)\n",
        "  return tf.keras.Sequential([\n",
        "      tf.keras.layers.Flatten(input_shape=[32, 32, 3]),\n",
        "      tf.keras.layers.Dense(100, activation='relu',\n",
        "                            kernel_initializer='he_normal'),\n",
        "      tf.keras.layers.Dense(100, activation='relu',\n",
        "                            kernel_initializer='he_normal'),\n",
        "      tf.keras.layers.Dense(100, activation='relu',\n",
        "                            kernel_initializer='he_normal'),\n",
        "      tf.keras.layers.Dens(10, activation='softmax')\n",
        "  ])\n",
        "\n",
        "  def build_and_train_model(optimizer):\n",
        "    model=build_model()\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer,\n",
        "                  metrics = ['accuracy'])\n",
        "    return model.fit(X_train, y_train, epochs = 10,\n",
        "                     validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "id": "ga4JN8T7oGfI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}